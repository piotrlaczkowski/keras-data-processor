{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf1f Welcome to Keras Data Processor - Preprocessing Power with TensorFlow Keras \ud83c\udf1f","text":"<p>** Welcome to the Future of Data Preprocessing!**</p> <p>Diving into the world of machine learning and data science, we often find ourselves tangled in the preprocessing jungle. Worry no more! Introducing a state-of-the-art data preprocessing model based on TensorFlow Keras and the innovative use of Keras preprocessing layers.</p> <p>Say goodbye to tedious data preparation tasks and hello to streamlined, efficient, and scalable data pipelines. Whether you're a seasoned data scientist or just starting out, this tool is designed to supercharge your ML workflows, making them more robust and faster than ever!</p>"},{"location":"#key-features","title":"\ud83d\udd11 Key Features:","text":"<ul> <li> <p>Automated Feature Engineering: Automatically detects and applies the optimal preprocessing steps for each feature type in your dataset.</p> </li> <li> <p>Customizable Preprocessing Pipelines: Tailor your preprocessing steps with ease, choosing from a wide range of options for numeric, categorical, and even complex feature crosses.</p> </li> <li> <p>Scalability and Efficiency: Designed for performance, handling large datasets with ease thanks to TensorFlow's powerful backend.</p> </li> <li> <p>Easy Integration: Seamlessly fits into your TensorFlow Keras models (as first layers of the mode), making it a breeze to go from raw data to trained model faster than ever.</p> </li> </ul>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting started:","text":"<p>We use poetry for handling dependencies so you will need to install it first. Then you can install the dependencies by running:</p> <p>To install dependencies:</p> <pre><code>poetry install\n</code></pre> <p>or to enter a dedicated env directly:</p> <pre><code>poetry shell\n</code></pre> <p>Then you can simply configure your preprocessor:</p>"},{"location":"#building-preprocessor","title":"\ud83d\udee0\ufe0f Building Preprocessor:","text":"<pre><code>from kdp import PreprocessingModel, FeatureType\n\n# DEFINING FEATURES PROCESSORS\nfeatures_spec = {\n    \"num_1\": FeatureType.FLOAT,\n    \"num_2\": \"float\",\n    \"cat_1\": FeatureType.STRING_CATEGORICAL,\n    \"cat_2\": FeatureType.INTEGER_CATEGORICAL,\n}\n\n# INSTANTIATE THE PREPROCESSING MODEL with your data\nppr = PreprocessingModel(\n    path_data=\"data/my_data.csv\",\n    features_specs=features_spec,\n)\n# construct the preprocessing pipelines\nppr.build_preprocessor()\n</code></pre> <p>This wil output:</p> <pre><code>{\n'model': &lt;Functional name=preprocessor, built=True&gt;,\n'inputs': {\n    'num_1': &lt;KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=num_1&gt;,\n    'num_2': &lt;KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=num_2&gt;,\n    'cat_1': &lt;KerasTensor shape=(None, 1), dtype=string, sparse=None, name=cat_1&gt;\n    'cat_2': &lt;KerasTensor shape=(None, 1), dtype=int32, sparse=None, name=cat_2&gt;,\n},\n'signature': {\n    'num_1': TensorSpec(shape=(None, 1), dtype=tf.float32, name='num_1'),\n    'num_2': TensorSpec(shape=(None, 1), dtype=tf.float32, name='num_2'),\n    'cat_1': TensorSpec(shape=(None, 1), dtype=tf.string, name='cat_1')\n    'cat_2': TensorSpec(shape=(None, 1), dtype=tf.int32, name='cat_2'),\n},\n'output_dims': 9\n}\n</code></pre> <p>This will result in the following preprocessing steps:</p> <p> </p>"},{"location":"#integrating-preprocessing-model-with-keras-model","title":"\ud83d\udd17 Integrating Preprocessing Model with Keras Model:","text":"<p>You can then easily ingetrate this model into your keras model as the first layer:</p> <pre><code>class FunctionalModelWithPreprocessing(tf.keras.Model):\n    def __init__(self, preprocessing_model: tf.keras.Model) -&gt; None:\n        \"\"\"Initialize the user model.\n\n        Args:\n            preprocessing_model (tf.keras.Model): The preprocessing model.\n        \"\"\"\n        super().__init__()\n        self.preprocessing_model = preprocessing_model\n\n        # Dynamically create inputs based on the preprocessing model's input shape\n        inputs = {\n            name: tf.keras.Input(shape=shape[1:], name=name)\n            for name, shape in self.preprocessing_model.input_shape.items()\n        }\n\n        # You can use the preprocessing model directly in the functional API.\n        x = self.preprocessing_model(inputs)\n\n        # Define the dense layer as part of the model architecture\n        output = tf.keras.layers.Dense(\n            units=128,\n            activation=\"relu\",\n        )(x)\n\n        # Use the Model's functional API to define inputs and outputs\n        self.model = tf.keras.Model(inputs=inputs, outputs=output)\n\n    def call(self, inputs: dict[str, tf.Tensor]) -&gt; tf.Tensor:\n        \"\"\"Call the item model with the given inputs.\"\"\"\n        return self.model(inputs)\n\n# not define the full model with builting preprocessing layers:\nfull_model = FunctionalModelWithPreprocessing(\n    preprocessing_model=ppr.model,\n)\n</code></pre>"},{"location":"#dive-deeper","title":"\ud83d\udd0d Dive Deeper:","text":"<p>Explore the detailed documentation to leverage the full potential of this preprocessing tool. Learn about customizing feature crosses, bucketization strategies, embedding sizes, and much more to truly tailor your preprocessing pipeline to your project's needs.</p>"},{"location":"contributing/","title":"\ud83d\udcbb Contributing: Join the Preprocessing Revolution! \ud83d\udee0\ufe0f","text":"<p>Eager to contribute? Great! We're excited to welcome new contributors to our project. Here's how you can get involved:</p>"},{"location":"contributing/#new-ideas-features-requests","title":"\ud83d\udca1 New Ideas / Features Requests","text":"<p>If you wan't to request a new feature or you have detected an issue, please use the following link: ISSUES</p>"},{"location":"contributing/#getting-started","title":"\ud83d\ude80 Getting Started:","text":"<ul> <li> <p> Fork the Repository: Visit our GitHub page, fork the repository, and clone it to your local machine.</p> </li> <li> <p> Set Up Your Environment: Make sure you have TensorFlow, Loguru, and all necessary dependencies installed.</p> </li> <li> <p> Make sure you have installed the pre-commit hook locally</p> </li> </ul> <p>??? installation-guide   Before using pre-commit hook you need to install it in your python environment.</p> <pre><code>    ```bash\n    conda install -c conda-forge pre-commit\n    ```\n\n    go to the root folder of this repository, activate your venv and use the following command:\n\n    ```bash\n    pre-commit install\n    ```\n</code></pre> <ul> <li> <p> Create a new branch to package your code</p> </li> <li> <p> Use standarized commit message:</p> </li> </ul> <p><code>{LABEL}(KDP): {message}</code></p> <p>This is very important for the automatic releases (semantic release) and to have clean history on the master branch.</p> <p>??? Labels-types</p> <pre><code>    | Label    | Usage                                                                                                                                                                                                                                             |\n    | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n    | break    | `break` is used to identify changes related to old compatibility or functionality that breaks the current usage (major)                                                                                                                           |\n    | feat     | `feat` is used to identify changes related to new backward-compatible abilities or functionality (minor)                                                                                                                                          |\n    | init     | `init` is used to indentify the starting related to the project (minor)                                                                                                                                                                           |\n    | enh      | `enh` is used to indentify changes related to amelioration of abilities or functionality (patch)                                                                                                                                                  |\n    | build    | `build` (also known as `chore`) is used to identify **development** changes related to the build system (involving scripts, configurations, or tools) and package dependencies (patch)                                                            |\n    | ci       | `ci` is used to identify **development** changes related to the continuous integration and deployment system - involving scripts, configurations, or tools (minor)                                                                                |\n    | docs     | `docs`  is used to identify documentation changes related to the project; whether intended externally for the end-users or internally for the developers (patch)                                                                                  |\n    | perf     | `perf`  is used to identify changes related to backward-compatible **performance improvements** (patch)                                                                                                                                           |\n    | refactor | `refactor` is used to identify changes related to modifying the codebase, which neither adds a feature nor fixes a bug - such as removing redundant code, simplifying the code, renaming variables, etc.&lt;br /&gt;i.e. handy for your wip ; ) (patch) |\n    | style    | `style`  is used to identify **development** changes related to styling the codebase, regardless of the meaning - such as indentations, semi-colons, quotes, trailing commas, and so on (patch)                                                   |\n    | test     | `test` is used to identify **development** changes related to tests - such as refactoring existing tests or adding new tests. (minor)                                                                                                             |\n    | fix      | `fix`  is used to identify changes related to backward-compatible bug fixes. (patch)                                                                                                                                                              |\n    | ops      | `ops` is used to identify changes related to deployment files like `values.yml`, `gateway.yml,` or `Jenkinsfile` in the **ops** directory. (minor)                                                                                                |\n    | hotfix   | `hotfix` is used to identify **production** changes related to backward-compatible bug fixes (patch)                                                                                                                                              |\n    | revert   | `revert` is used to identify backward changes (patch)                                                                                                                                                                                             |\n    | maint    | `maint` is used to identify **maintenance** changes related to project (patch)                                                                                                                                                                    |\n</code></pre> <ul> <li> Create your first Merge Request (MR) as soon as possible.</li> </ul> <p>Merge requests will be responsible for semantic-release storytelling and so use them wisely! The changelog report generated automatically will be based on your commits merged into main branch and should cover all the thins you did for the project, as an example:</p> <ul> <li> Separate your merge requests based on LABEL or functionality if you are working on <code>feat</code> label</li> </ul> <p>This about what part of feature you are working on, (messages) i.e.:</p> <pre><code>    - `initializaing base pre-processing code`\n    - `init repo structure`\n    - `adding pre-processing unit-tests`\n</code></pre> <ul> <li> Once the code is ready create a Merge Request (MR) into the DEV branch with a proper naming convention</li> </ul> <p>The name of your MR should follow the same exact convention as your commits (we have a dedicated check for this in the CI):</p> <pre><code>    `{LABEL}(KDP): {message}`\n</code></pre> <ul> <li> <p> Use small Merge Requests but do them more ofthen &lt; 400 ligns for quicker and simple review and not the whole project !</p> </li> <li> <p> Ask for a Code Review !</p> </li> <li> <p> Once your MR is approved, solve all your unresolved conversation and pass all the CI check before you can merge it.</p> </li> <li> <p> All the Tests for your code should pass -&gt; REMEMBER NO TESTS = NO MERGE \ud83d\udea8</p> </li> </ul>"}]}